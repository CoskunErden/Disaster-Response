{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/ef/bcd79e8d59250d6e8478eb1290dc6e05be42b3be8a86e3954146adbc171a/scikit_learn-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.0MB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.2.1)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.11)\n",
      "Collecting numpy>=1.13.3 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl (13.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.4MB 2.6MB/s eta 0:00:01\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, numpy, scikit-learn\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: scikit-learn 0.19.1\n",
      "    Uninstalling scikit-learn-0.19.1:\n",
      "      Successfully uninstalled scikit-learn-0.19.1\n",
      "Successfully installed numpy-1.19.5 scikit-learn-0.24.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.2.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from utils import tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterPrediction.db')\n",
    "df = pd.read_sql('SELECT * FROM disaster_project', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0        0      0            0             0                 0      ...         \n",
       "1        0      0            1             0                 0      ...         \n",
       "2        0      0            0             0                 0      ...         \n",
       "3        1      0            1             0                 1      ...         \n",
       "4        0      0            0             0                 0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26216 entries, 0 to 26215\n",
      "Data columns (total 40 columns):\n",
      "id                        26216 non-null int64\n",
      "message                   26216 non-null object\n",
      "original                  10170 non-null object\n",
      "genre                     26216 non-null object\n",
      "related                   26216 non-null int64\n",
      "request                   26216 non-null int64\n",
      "offer                     26216 non-null int64\n",
      "aid_related               26216 non-null int64\n",
      "medical_help              26216 non-null int64\n",
      "medical_products          26216 non-null int64\n",
      "search_and_rescue         26216 non-null int64\n",
      "security                  26216 non-null int64\n",
      "military                  26216 non-null int64\n",
      "child_alone               26216 non-null int64\n",
      "water                     26216 non-null int64\n",
      "food                      26216 non-null int64\n",
      "shelter                   26216 non-null int64\n",
      "clothing                  26216 non-null int64\n",
      "money                     26216 non-null int64\n",
      "missing_people            26216 non-null int64\n",
      "refugees                  26216 non-null int64\n",
      "death                     26216 non-null int64\n",
      "other_aid                 26216 non-null int64\n",
      "infrastructure_related    26216 non-null int64\n",
      "transport                 26216 non-null int64\n",
      "buildings                 26216 non-null int64\n",
      "electricity               26216 non-null int64\n",
      "tools                     26216 non-null int64\n",
      "hospitals                 26216 non-null int64\n",
      "shops                     26216 non-null int64\n",
      "aid_centers               26216 non-null int64\n",
      "other_infrastructure      26216 non-null int64\n",
      "weather_related           26216 non-null int64\n",
      "floods                    26216 non-null int64\n",
      "storm                     26216 non-null int64\n",
      "fire                      26216 non-null int64\n",
      "earthquake                26216 non-null int64\n",
      "cold                      26216 non-null int64\n",
      "other_weather             26216 non-null int64\n",
      "direct_report             26216 non-null int64\n",
      "dtypes: int64(37), object(3)\n",
      "memory usage: 8.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# define feature and target variables X and Y\n",
    "X = df['message'].values\n",
    "\n",
    "print(type(X))\n",
    "Y = df.iloc[:, 4:].values\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize the input text by converting to lowercase, removing punctuation, \n",
    "    tokenizing the text, and removing stopwords.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to tokenize.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tokens with punctuation removed and stopwords filtered out.\n",
    "    \"\"\"\n",
    "    # convert the input text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # clear the punctuation\n",
    "    text = re.sub(r\"[^0-9a-zA-Z]\", \" \", text)\n",
    "\n",
    "    # tokenize text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Apply lemmatization to each word (token) in the tokenized list, ignoring stopwords\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in words if w not in stopwords.words(\"english\")]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize function is written in a seperate file 'tokenize.py' because of the errors encountered in pickle function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipeline_lr = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),   # Tokenize the message column\n",
    "            ('tfidf', TfidfTransformer())                    # Transform into TF-IDF\n",
    "        ]))\n",
    "    ])),\n",
    "    ('clf', MultiOutputClassifier(LogisticRegression(max_iter=1000)))  # Apply Logistic Regression\n",
    "])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-269effed66b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipeline_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 **fit_params_validated)\n\u001b[0;32m--> 182\u001b[0;31m             for i in range(y.shape[1]))\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m   1375\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "pipeline_lr.fit(X_train, Y_train)\n",
    "\n",
    "# make predictions\n",
    "Y_pred = pipeline_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 9 has only one class: {0}\n"
     ]
    }
   ],
   "source": [
    "# Check if there are columns with only one class in the target variables\n",
    "for i, column in enumerate(Y_train.T):\n",
    "    unique_values = set(column)\n",
    "    if len(unique_values) == 1:\n",
    "        print(f\"Column {i} has only one class: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with only one class from Y_train and Y_test\n",
    "columns_to_drop = [i for i, column in enumerate(Y_train.T) if len(set(column)) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with only one class from Y_train and Y_test\n",
    "\n",
    "Y_train_filtered = np.delete(Y_train, columns_to_drop, axis=1)\n",
    "Y_test_filtered = np.delete(Y_test, columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "pipeline_lr.fit(X_train, Y_train_filtered)\n",
    "\n",
    "# make predictions\n",
    "Y_pred_filtered = pipeline_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[1 1 0 ... 0 0 1]\n",
    " [1 0 0 ... 0 0 0]\n",
    " [1 0 0 ... 0 0 0]\n",
    " ...\n",
    " [1 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.55      1873\n",
      "           1       0.84      0.94      0.89      5934\n",
      "           2       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.82      7865\n",
      "   macro avg       0.52      0.47      0.48      7865\n",
      "weighted avg       0.80      0.82      0.80      7865\n",
      "\n",
      "Category 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      6533\n",
      "           1       0.83      0.53      0.65      1332\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.87      0.75      0.80      7865\n",
      "weighted avg       0.90      0.90      0.89      7865\n",
      "\n",
      "Category 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7829\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "Category 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      4646\n",
      "           1       0.76      0.66      0.71      3219\n",
      "\n",
      "    accuracy                           0.78      7865\n",
      "   macro avg       0.77      0.76      0.76      7865\n",
      "weighted avg       0.78      0.78      0.77      7865\n",
      "\n",
      "Category 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7227\n",
      "           1       0.64      0.14      0.23       638\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.79      0.57      0.60      7865\n",
      "weighted avg       0.91      0.92      0.90      7865\n",
      "\n",
      "Category 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7447\n",
      "           1       0.83      0.16      0.27       418\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.89      0.58      0.62      7865\n",
      "weighted avg       0.95      0.95      0.94      7865\n",
      "\n",
      "Category 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7673\n",
      "           1       1.00      0.05      0.10       192\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.99      0.53      0.54      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7721\n",
      "           1       0.00      0.00      0.00       144\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "Category 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7620\n",
      "           1       0.55      0.07      0.13       245\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.76      0.54      0.56      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "Category 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      7365\n",
      "           1       0.80      0.46      0.58       500\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.88      0.72      0.78      7865\n",
      "weighted avg       0.95      0.96      0.95      7865\n",
      "\n",
      "Category 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      6987\n",
      "           1       0.86      0.58      0.69       878\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.91      0.78      0.83      7865\n",
      "weighted avg       0.94      0.94      0.94      7865\n",
      "\n",
      "Category 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      7160\n",
      "           1       0.80      0.44      0.57       705\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.88      0.71      0.77      7865\n",
      "weighted avg       0.93      0.94      0.93      7865\n",
      "\n",
      "Category 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7750\n",
      "           1       0.76      0.11      0.20       115\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.88      0.56      0.60      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7695\n",
      "           1       0.61      0.06      0.12       170\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.80      0.53      0.55      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "Category 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7773\n",
      "           1       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 15:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7605\n",
      "           1       0.68      0.05      0.09       260\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.83      0.52      0.54      7865\n",
      "weighted avg       0.96      0.97      0.95      7865\n",
      "\n",
      "Category 16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7499\n",
      "           1       0.90      0.24      0.38       366\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.93      0.62      0.68      7865\n",
      "weighted avg       0.96      0.96      0.95      7865\n",
      "\n",
      "Category 17:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      6832\n",
      "           1       0.58      0.11      0.18      1033\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.73      0.55      0.56      7865\n",
      "weighted avg       0.84      0.87      0.83      7865\n",
      "\n",
      "Category 18:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7360\n",
      "           1       0.62      0.03      0.06       505\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.78      0.52      0.51      7865\n",
      "weighted avg       0.92      0.94      0.91      7865\n",
      "\n",
      "Category 19:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7503\n",
      "           1       0.82      0.07      0.14       362\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.89      0.54      0.56      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "Category 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7473\n",
      "           1       0.86      0.21      0.33       392\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.91      0.60      0.66      7865\n",
      "weighted avg       0.96      0.96      0.95      7865\n",
      "\n",
      "Category 21:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7697\n",
      "           1       0.86      0.11      0.20       168\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.92      0.56      0.60      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 22:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7817\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "Category 23:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7787\n",
      "           1       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.99      7865\n",
      "\n",
      "Category 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7837\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "Category 25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7762\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.99      0.98      7865\n",
      "\n",
      "Category 26:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7524\n",
      "           1       0.57      0.01      0.02       341\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.76      0.51      0.50      7865\n",
      "weighted avg       0.94      0.96      0.94      7865\n",
      "\n",
      "Category 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      5702\n",
      "           1       0.85      0.65      0.73      2163\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.86      0.80      0.82      7865\n",
      "weighted avg       0.87      0.87      0.87      7865\n",
      "\n",
      "Category 28:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7242\n",
      "           1       0.91      0.43      0.58       623\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.93      0.71      0.78      7865\n",
      "weighted avg       0.95      0.95      0.94      7865\n",
      "\n",
      "Category 29:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      7127\n",
      "           1       0.76      0.44      0.56       738\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.85      0.71      0.76      7865\n",
      "weighted avg       0.93      0.93      0.93      7865\n",
      "\n",
      "Category 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7782\n",
      "           1       0.33      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.66      0.51      0.51      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 31:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      7163\n",
      "           1       0.89      0.67      0.76       702\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.93      0.83      0.87      7865\n",
      "weighted avg       0.96      0.96      0.96      7865\n",
      "\n",
      "Category 32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7694\n",
      "           1       0.83      0.09      0.16       171\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.91      0.54      0.57      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 33:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7450\n",
      "           1       0.58      0.03      0.06       415\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.77      0.52      0.52      7865\n",
      "weighted avg       0.93      0.95      0.93      7865\n",
      "\n",
      "Category 34:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      6321\n",
      "           1       0.75      0.42      0.54      1544\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.81      0.69      0.73      7865\n",
      "weighted avg       0.85      0.86      0.84      7865\n",
      "\n",
      "Overall F1 Score: 0.9363\n",
      "Overall Precision: 0.9389\n",
      "Overall Recall: 0.9471\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store metrics for each category\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# Iterate through each column of the output categories\n",
    "for i, column in enumerate(Y_test_filtered.T):\n",
    "    print(f\"Category {i}:\")\n",
    "    \n",
    "    # Generate the classification report\n",
    "    report = classification_report(Y_test_filtered[:, i], Y_pred_filtered[:, i], zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "    # Optionally, extract F1, precision, and recall scores from the report\n",
    "    # Parse the classification report into a dictionary\n",
    "    report_dict = classification_report(Y_test_filtered[:, i], Y_pred_filtered[:, i], output_dict=True, zero_division=0)\n",
    "    \n",
    "    # Append the 'weighted avg' scores to the lists\n",
    "    f1_scores.append(report_dict['weighted avg']['f1-score'])\n",
    "    precisions.append(report_dict['weighted avg']['precision'])\n",
    "    recalls.append(report_dict['weighted avg']['recall'])\n",
    "\n",
    "# Print out the average metrics across all categories\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_recall = sum(recalls) / len(recalls)\n",
    "\n",
    "print(f\"Overall F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"Overall Precision: {avg_precision:.4f}\")\n",
    "print(f\"Overall Recall: {avg_recall:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall performance of the model achieved an F1 score of 0.9363, with an overall precision of 0.9389 and an overall recall of 0.9471. These metrics provide a good balance between precision and recall across all categories, reflecting the model's general effectiveness in the multi-class classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall performance of the model achieved an F1 score of 0.9363, with an overall precision of 0.9389 and an overall recall of 0.9471. These metrics provide a good balance between precision and recall across all categories, reflecting the model's general effectiveness in the multi-class classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] END clf__estimator__C=0.1, clf__estimator__max_iter=1000; total time= 1.9min\n",
      "[CV] END clf__estimator__C=0.1, clf__estimator__max_iter=1000; total time= 1.9min\n",
      "[CV] END clf__estimator__C=0.1, clf__estimator__max_iter=1000; total time= 2.0min\n",
      "[CV] END clf__estimator__C=0.1, clf__estimator__max_iter=2000; total time= 1.9min\n",
      "[CV] END clf__estimator__C=0.1, clf__estimator__max_iter=2000; total time= 1.9min\n",
      "[CV] END clf__estimator__C=0.1, clf__estimator__max_iter=2000; total time= 1.9min\n",
      "[CV] END .clf__estimator__C=1, clf__estimator__max_iter=1000; total time= 3.0min\n",
      "[CV] END .clf__estimator__C=1, clf__estimator__max_iter=1000; total time= 3.1min\n",
      "[CV] END .clf__estimator__C=1, clf__estimator__max_iter=1000; total time= 3.4min\n",
      "[CV] END .clf__estimator__C=1, clf__estimator__max_iter=2000; total time= 3.1min\n",
      "[CV] END .clf__estimator__C=1, clf__estimator__max_iter=2000; total time= 3.1min\n",
      "[CV] END .clf__estimator__C=1, clf__estimator__max_iter=2000; total time= 3.3min\n",
      "[CV] END clf__estimator__C=10, clf__estimator__max_iter=1000; total time= 6.2min\n",
      "[CV] END clf__estimator__C=10, clf__estimator__max_iter=1000; total time= 6.5min\n",
      "[CV] END clf__estimator__C=10, clf__estimator__max_iter=1000; total time= 6.2min\n",
      "[CV] END clf__estimator__C=10, clf__estimator__max_iter=2000; total time= 6.4min\n",
      "[CV] END clf__estimator__C=10, clf__estimator__max_iter=2000; total time= 6.4min\n",
      "[CV] END clf__estimator__C=10, clf__estimator__max_iter=2000; total time= 6.1min\n",
      "Best Parameters: {'clf__estimator__C': 1, 'clf__estimator__max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter grid for grid search\n",
    "parameters_lr = {\n",
    "    'clf__estimator__C': [0.1, 1, 10],  # Regularization strength\n",
    "    'clf__estimator__max_iter': [1000, 2000]  # Ensure at least 1000 iterations for convergence\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline_lr, param_grid=parameters_lr, verbose=2, n_jobs=1, cv=3)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, Y_train_filtered)\n",
    "\n",
    "# Display the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: {'clf__estimator__C': 1, 'clf__estimator__max_iter': 1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.55      1873\n",
      "           1       0.84      0.94      0.89      5934\n",
      "           2       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.82      7865\n",
      "   macro avg       0.52      0.47      0.48      7865\n",
      "weighted avg       0.80      0.82      0.80      7865\n",
      "\n",
      "Category 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      6533\n",
      "           1       0.83      0.53      0.65      1332\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.87      0.75      0.80      7865\n",
      "weighted avg       0.90      0.90      0.89      7865\n",
      "\n",
      "Category 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7829\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "Category 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      4646\n",
      "           1       0.76      0.66      0.71      3219\n",
      "\n",
      "    accuracy                           0.78      7865\n",
      "   macro avg       0.77      0.76      0.76      7865\n",
      "weighted avg       0.78      0.78      0.77      7865\n",
      "\n",
      "Category 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7227\n",
      "           1       0.64      0.14      0.23       638\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.79      0.57      0.60      7865\n",
      "weighted avg       0.91      0.92      0.90      7865\n",
      "\n",
      "Category 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7447\n",
      "           1       0.83      0.16      0.27       418\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.89      0.58      0.62      7865\n",
      "weighted avg       0.95      0.95      0.94      7865\n",
      "\n",
      "Category 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7673\n",
      "           1       1.00      0.05      0.10       192\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.99      0.53      0.54      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7721\n",
      "           1       0.00      0.00      0.00       144\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "Category 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7620\n",
      "           1       0.55      0.07      0.13       245\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.76      0.54      0.56      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "Category 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      7365\n",
      "           1       0.80      0.46      0.58       500\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.88      0.72      0.78      7865\n",
      "weighted avg       0.95      0.96      0.95      7865\n",
      "\n",
      "Category 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      6987\n",
      "           1       0.86      0.58      0.69       878\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.91      0.78      0.83      7865\n",
      "weighted avg       0.94      0.94      0.94      7865\n",
      "\n",
      "Category 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      7160\n",
      "           1       0.80      0.44      0.57       705\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.88      0.71      0.77      7865\n",
      "weighted avg       0.93      0.94      0.93      7865\n",
      "\n",
      "Category 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7750\n",
      "           1       0.76      0.11      0.20       115\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.88      0.56      0.60      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7695\n",
      "           1       0.61      0.06      0.12       170\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.80      0.53      0.55      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "Category 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7773\n",
      "           1       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 15:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7605\n",
      "           1       0.68      0.05      0.09       260\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.83      0.52      0.54      7865\n",
      "weighted avg       0.96      0.97      0.95      7865\n",
      "\n",
      "Category 16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7499\n",
      "           1       0.90      0.24      0.38       366\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.93      0.62      0.68      7865\n",
      "weighted avg       0.96      0.96      0.95      7865\n",
      "\n",
      "Category 17:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      6832\n",
      "           1       0.58      0.11      0.18      1033\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.73      0.55      0.56      7865\n",
      "weighted avg       0.84      0.87      0.83      7865\n",
      "\n",
      "Category 18:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7360\n",
      "           1       0.62      0.03      0.06       505\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.78      0.52      0.51      7865\n",
      "weighted avg       0.92      0.94      0.91      7865\n",
      "\n",
      "Category 19:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7503\n",
      "           1       0.82      0.07      0.14       362\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.89      0.54      0.56      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "Category 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7473\n",
      "           1       0.86      0.21      0.33       392\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.91      0.60      0.66      7865\n",
      "weighted avg       0.96      0.96      0.95      7865\n",
      "\n",
      "Category 21:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7697\n",
      "           1       0.86      0.11      0.20       168\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.92      0.56      0.60      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 22:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7817\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "Category 23:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7787\n",
      "           1       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.99      7865\n",
      "\n",
      "Category 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7837\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "Category 25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7762\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.99      0.98      7865\n",
      "\n",
      "Category 26:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7524\n",
      "           1       0.57      0.01      0.02       341\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.76      0.51      0.50      7865\n",
      "weighted avg       0.94      0.96      0.94      7865\n",
      "\n",
      "Category 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      5702\n",
      "           1       0.85      0.65      0.73      2163\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.86      0.80      0.82      7865\n",
      "weighted avg       0.87      0.87      0.87      7865\n",
      "\n",
      "Category 28:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7242\n",
      "           1       0.91      0.43      0.58       623\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.93      0.71      0.78      7865\n",
      "weighted avg       0.95      0.95      0.94      7865\n",
      "\n",
      "Category 29:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      7127\n",
      "           1       0.76      0.44      0.56       738\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.85      0.71      0.76      7865\n",
      "weighted avg       0.93      0.93      0.93      7865\n",
      "\n",
      "Category 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7782\n",
      "           1       0.33      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.66      0.51      0.51      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 31:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      7163\n",
      "           1       0.89      0.67      0.76       702\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.93      0.83      0.87      7865\n",
      "weighted avg       0.96      0.96      0.96      7865\n",
      "\n",
      "Category 32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7694\n",
      "           1       0.83      0.09      0.16       171\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.91      0.54      0.57      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 33:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7450\n",
      "           1       0.58      0.03      0.06       415\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.77      0.52      0.52      7865\n",
      "weighted avg       0.93      0.95      0.93      7865\n",
      "\n",
      "Category 34:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      6321\n",
      "           1       0.75      0.42      0.54      1544\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.81      0.69      0.73      7865\n",
      "weighted avg       0.85      0.86      0.84      7865\n",
      "\n",
      "Overall Logistic Regression Precision: 0.9389\n",
      "Overall Logistic Regression Recall: 0.9471\n",
      "Overall Logistic Regression F1-Score: 0.9363\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model using the best parameters from GridSearchCV\n",
    "best_pipeline_lr = grid_search.best_estimator_\n",
    "\n",
    "# Fit the model with the entire training set\n",
    "best_pipeline_lr.fit(X_train, Y_train_filtered)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_filtered = best_pipeline_lr.predict(X_test)\n",
    "\n",
    "# Initialize lists to store precision, recall, and f1 scores for each category\n",
    "lr_precisions = []\n",
    "lr_recalls = []\n",
    "lr_f1s = []\n",
    "\n",
    "# Now, test the model using classification_report and other metrics\n",
    "for i, column in enumerate(Y_test_filtered.T):\n",
    "    print(f\"Category {i}:\")\n",
    "\n",
    "    # Generate the classification report for each category\n",
    "    report = classification_report(Y_test_filtered[:, i], Y_pred_filtered[:, i], output_dict=True, zero_division=0)\n",
    "    \n",
    "    # Print detailed classification report for each category\n",
    "    print(classification_report(Y_test_filtered[:, i], Y_pred_filtered[:, i], zero_division=0))\n",
    "\n",
    "    # Append 'weighted avg' precision, recall, and f1-score to the lists\n",
    "    lr_precisions.append(report['weighted avg']['precision'])\n",
    "    lr_recalls.append(report['weighted avg']['recall'])\n",
    "    lr_f1s.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "# Calculate overall average metrics for Logistic Regression\n",
    "avg_lr_precision = sum(lr_precisions) / len(lr_precisions)\n",
    "avg_lr_recall = sum(lr_recalls) / len(lr_recalls)\n",
    "avg_lr_f1 = sum(lr_f1s) / len(lr_f1s)\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"Overall Logistic Regression Precision: {avg_lr_precision:.4f}\")\n",
    "print(f\"Overall Logistic Regression Recall: {avg_lr_recall:.4f}\")\n",
    "print(f\"Overall Logistic Regression F1-Score: {avg_lr_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall performance of the Logistic Regression model is summarized as follows: it achieved a precision of 93.89%, a recall of 94.71%, and an F1-Score of 93.63%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning model for categorizing disaster response messages performed well overall, with high accuracy and precision across most categories.\n",
    "\n",
    "Overall Accuracy: 94.41%\n",
    "Overall Precision: 93.29%\n",
    "Overall Recall: 94.41%\n",
    "Key Categories:\n",
    "Related: Precision 84%, Recall 90%, F1-score 87%\n",
    "Request: Precision 81%, Recall 43%, F1-score 57%\n",
    "Aid Related: Precision 73%, Recall 62%, F1-score 67%\n",
    "Notable Observations:\n",
    "Strong Performance: Categories like 'related', 'aid_related', and 'weather_related' have high precision and recall, indicating the model can effectively classify these common categories.\n",
    "Weak Performance: Categories such as 'medical_help' and 'direct_report' had low recall (9% and 34%, respectively), suggesting the model struggles with these less frequent or more complex categories.\n",
    "Imbalance Impact: Categories with very few samples, such as 'offer' and 'tools', had ill-defined precision and F1-scores, signaling the model's difficulty in predicting these rare categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.41      0.51      1873\n",
      "           1       0.83      0.94      0.88      5934\n",
      "           2       0.37      0.29      0.33        58\n",
      "\n",
      "    accuracy                           0.81      7865\n",
      "   macro avg       0.63      0.55      0.57      7865\n",
      "weighted avg       0.79      0.81      0.79      7865\n",
      "\n",
      "Category 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      6533\n",
      "           1       0.84      0.50      0.62      1332\n",
      "\n",
      "    accuracy                           0.90      7865\n",
      "   macro avg       0.87      0.74      0.78      7865\n",
      "weighted avg       0.89      0.90      0.89      7865\n",
      "\n",
      "Category 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7829\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "Category 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      4646\n",
      "           1       0.74      0.69      0.71      3219\n",
      "\n",
      "    accuracy                           0.77      7865\n",
      "   macro avg       0.77      0.76      0.76      7865\n",
      "weighted avg       0.77      0.77      0.77      7865\n",
      "\n",
      "Category 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7227\n",
      "           1       0.62      0.08      0.15       638\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.77      0.54      0.55      7865\n",
      "weighted avg       0.90      0.92      0.89      7865\n",
      "\n",
      "Category 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7447\n",
      "           1       0.83      0.08      0.15       418\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.89      0.54      0.56      7865\n",
      "weighted avg       0.94      0.95      0.93      7865\n",
      "\n",
      "Category 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7673\n",
      "           1       0.69      0.10      0.18       192\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.83      0.55      0.58      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "Category 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7721\n",
      "           1       0.00      0.00      0.00       144\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "Category 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7620\n",
      "           1       0.54      0.06      0.10       245\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.75      0.53      0.54      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "Category 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7365\n",
      "           1       0.87      0.34      0.48       500\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.91      0.67      0.73      7865\n",
      "weighted avg       0.95      0.95      0.94      7865\n",
      "\n",
      "Category 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      6987\n",
      "           1       0.87      0.60      0.71       878\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.91      0.79      0.84      7865\n",
      "weighted avg       0.94      0.95      0.94      7865\n",
      "\n",
      "Category 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      7160\n",
      "           1       0.81      0.30      0.44       705\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.87      0.65      0.70      7865\n",
      "weighted avg       0.92      0.93      0.92      7865\n",
      "\n",
      "Category 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7750\n",
      "           1       0.79      0.10      0.17       115\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.89      0.55      0.58      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7695\n",
      "           1       0.88      0.04      0.08       170\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.93      0.52      0.53      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7773\n",
      "           1       0.00      0.00      0.00        92\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "Category 15:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7605\n",
      "           1       0.43      0.01      0.02       260\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.70      0.51      0.50      7865\n",
      "weighted avg       0.95      0.97      0.95      7865\n",
      "\n",
      "Category 16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7499\n",
      "           1       0.91      0.11      0.20       366\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.93      0.56      0.59      7865\n",
      "weighted avg       0.96      0.96      0.94      7865\n",
      "\n",
      "Category 17:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      6832\n",
      "           1       0.57      0.04      0.07      1033\n",
      "\n",
      "    accuracy                           0.87      7865\n",
      "   macro avg       0.72      0.52      0.50      7865\n",
      "weighted avg       0.83      0.87      0.82      7865\n",
      "\n",
      "Category 18:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7360\n",
      "           1       0.00      0.00      0.00       505\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.47      0.50      0.48      7865\n",
      "weighted avg       0.88      0.94      0.90      7865\n",
      "\n",
      "Category 19:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7503\n",
      "           1       0.74      0.10      0.18       362\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.85      0.55      0.58      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "Category 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7473\n",
      "           1       0.86      0.12      0.21       392\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.91      0.56      0.60      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "Category 21:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7697\n",
      "           1       0.88      0.04      0.08       168\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.93      0.52      0.53      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 22:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7817\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "Category 23:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7787\n",
      "           1       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.99      7865\n",
      "\n",
      "Category 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7837\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "Category 25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7762\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.99      0.98      7865\n",
      "\n",
      "Category 26:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7524\n",
      "           1       0.00      0.00      0.00       341\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.92      0.96      0.94      7865\n",
      "\n",
      "Category 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      5702\n",
      "           1       0.84      0.70      0.76      2163\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.87      0.83      0.84      7865\n",
      "weighted avg       0.88      0.88      0.88      7865\n",
      "\n",
      "Category 28:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      7242\n",
      "           1       0.88      0.46      0.61       623\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.92      0.73      0.79      7865\n",
      "weighted avg       0.95      0.95      0.95      7865\n",
      "\n",
      "Category 29:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      7127\n",
      "           1       0.78      0.55      0.64       738\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.86      0.76      0.80      7865\n",
      "weighted avg       0.94      0.94      0.94      7865\n",
      "\n",
      "Category 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7782\n",
      "           1       1.00      0.01      0.02        83\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.99      0.51      0.51      7865\n",
      "weighted avg       0.99      0.99      0.98      7865\n",
      "\n",
      "Category 31:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7163\n",
      "           1       0.88      0.79      0.83       702\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.93      0.89      0.91      7865\n",
      "weighted avg       0.97      0.97      0.97      7865\n",
      "\n",
      "Category 32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7694\n",
      "           1       0.83      0.11      0.20       171\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.90      0.56      0.59      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "Category 33:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7450\n",
      "           1       0.75      0.02      0.04       415\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.85      0.51      0.51      7865\n",
      "weighted avg       0.94      0.95      0.92      7865\n",
      "\n",
      "Category 34:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      6321\n",
      "           1       0.77      0.35      0.48      1544\n",
      "\n",
      "    accuracy                           0.85      7865\n",
      "   macro avg       0.81      0.66      0.70      7865\n",
      "weighted avg       0.84      0.85      0.83      7865\n",
      "\n",
      "Overall Random Forest Precision: 0.9361\n",
      "Overall Random Forest Recall: 0.9463\n",
      "Overall Random Forest F1-Score: 0.9341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pipeline for processing the message (text) with TF-IDF and Random Forest\n",
    "pipeline_rf = Pipeline([\n",
    "    ('text_pipeline', Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),  # Tokenize the message column\n",
    "        ('tfidf', TfidfTransformer())                  # Transform into TF-IDF\n",
    "    ])),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))  # Apply Random Forest for multi-output classification\n",
    "])\n",
    "\n",
    "# Train the Random Forest model\n",
    "pipeline_rf.fit(X_train, Y_train_filtered)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_filtered = pipeline_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model using classification_report for each category\n",
    "for i, column in enumerate(Y_test_filtered.T):\n",
    "    print(f\"Category {i}:\")\n",
    "    print(classification_report(Y_test_filtered[:, i], Y_pred_filtered[:, i], zero_division=0))\n",
    "\n",
    "# Calculate overall precision, recall, and F1-score across all categories\n",
    "rf_precisions = []\n",
    "rf_recalls = []\n",
    "rf_f1s = []\n",
    "\n",
    "# Iterate through each category\n",
    "for i, column in enumerate(Y_test_filtered.T):\n",
    "    report = classification_report(Y_test_filtered[:, i], Y_pred_filtered[:, i], output_dict=True, zero_division=0)\n",
    "    rf_precisions.append(report['weighted avg']['precision'])\n",
    "    rf_recalls.append(report['weighted avg']['recall'])\n",
    "    rf_f1s.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "# Calculate overall average metrics for Random Forest\n",
    "avg_rf_precision = sum(rf_precisions) / len(rf_precisions)\n",
    "avg_rf_recall = sum(rf_recalls) / len(rf_recalls)\n",
    "avg_rf_f1 = sum(rf_f1s) / len(rf_f1s)\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"Overall Random Forest Precision: {avg_rf_precision:.4f}\")\n",
    "print(f\"Overall Random Forest Recall: {avg_rf_recall:.4f}\")\n",
    "print(f\"Overall Random Forest F1-Score: {avg_rf_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model performed well, achieving an overall precision of 93.61%, a recall of 94.63%, and an F1-score of 93.41%. These metrics indicate that the model is highly effective at correctly identifying relevant instances, with a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and Compare Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the performance of the Random Forest and Logistic Regression models, both demonstrate strong classification capabilities. The Random Forest model achieved a precision of 93.61%, a recall of 94.63%, and an F1-score of 93.41%. Meanwhile, the Logistic Regression model performed slightly better, with a precision of 93.89%, a recall of 94.71%, and an F1-score of 93.63%. While the differences in performance metrics are minimal, Logistic Regression edges out Random Forest in terms of overall precision, recall, and F1-score, suggesting that it might be more effective at correctly identifying positive instances in this particular case. Both models are highly comparable and perform similarly well.However, the Logistic Regression model slightly outperforms the Random Forest model, achieving a precision of 93.89%, a recall of 94.71%, and an F1-score of 93.63%. In comparison, the Random Forest model has a precision of 93.61%, a recall of 94.63%, and an F1-score of 93.41%. While both models perform well, Logistic Regression shows marginally better results in all three metrics, indicating it may be the more effective model for this particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the pipeline with the custom tokenize function and Logistic Regression model with best parameters\n",
    "pipeline_lr = Pipeline([\n",
    "    ('vect', TfidfVectorizer(tokenizer=tokenize)),  # Use custom tokenize function\n",
    "    ('clf', MultiOutputClassifier(LogisticRegression(C=1, max_iter=1000)))  # Apply Logistic Regression\n",
    "])\n",
    "\n",
    "\n",
    "# Fit the model on your training data\n",
    "pipeline_lr.fit(X_train, Y_train_filtered)\n",
    "\n",
    "\n",
    "\n",
    "# Save the Logistic Regression pipeline model to a pickle file\n",
    "with open('logistic_regression_pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline_lr, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_pipeline.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the pipeline with the custom tokenize function and Logistic Regression model with best parameters\n",
    "pipeline_lr = Pipeline([\n",
    "    ('vect', TfidfVectorizer(tokenizer=tokenize, token_pattern=None)),  # Use custom tokenize function\n",
    "    ('clf', MultiOutputClassifier(LogisticRegression(C=1, max_iter=1000)))  # Apply Logistic Regression\n",
    "])\n",
    "\n",
    "# Fit the model on your training data\n",
    "pipeline_lr.fit(X_train, Y_train_filtered)\n",
    "\n",
    "# Save the Logistic Regression pipeline model to a file\n",
    "joblib.dump(pipeline_lr, 'logistic_regression_pipeline.pkl', compress=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train_classifier.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "def load_data(data_file):\n",
    "    \"\"\"\n",
    "    Load the data from the specified CSV file, clean it, and return the features and labels.\n",
    "\n",
    "    Args:\n",
    "    data_file (str): The file path of the CSV file containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "    X (DataFrame): The features (messages).\n",
    "    y (DataFrame): The labels (categories).\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    # Assuming 'message' is the feature column and columns starting from index 4 are labels\n",
    "    X = df['message']\n",
    "    y = df.iloc[:, 4:]  # Adjust based on the column index where labels start\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    Build a machine learning pipeline with TfidfVectorizer and Logistic Regression,\n",
    "    and set up a GridSearchCV for hyperparameter tuning.\n",
    "\n",
    "    Returns:\n",
    "    model (GridSearchCV): The model pipeline with GridSearchCV.\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer(tokenizer=tokenize, token_pattern=None)),\n",
    "        ('clf', MultiOutputClassifier(LogisticRegression(max_iter=1000)))\n",
    "    ])\n",
    "\n",
    "    # Define hyperparameters for GridSearchCV\n",
    "    parameters = {\n",
    "        'vect__max_df': [0.9, 1.0],\n",
    "        'clf__estimator__C': [1, 10]\n",
    "    }\n",
    "\n",
    "    # Grid search for hyperparameter tuning\n",
    "    model_pipeline = GridSearchCV(pipeline, param_grid=parameters, verbose=3, cv=3)\n",
    "\n",
    "    return model_pipeline\n",
    "\n",
    "def train(X, y, model):\n",
    "    \"\"\"\n",
    "    Train the model on the training data, evaluate it on the test set,\n",
    "    and output classification reports for each category.\n",
    "\n",
    "    Args:\n",
    "    X (DataFrame): The features.\n",
    "    y (DataFrame): The labels.\n",
    "    model (GridSearchCV): The model pipeline.\n",
    "\n",
    "    Returns:\n",
    "    model: The trained model.\n",
    "    \"\"\"\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Output classification report for each category\n",
    "    for i, col in enumerate(y.columns):\n",
    "        print(f'Category: {col}')\n",
    "        print(classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def export_model(model, model_filepath):\n",
    "    \"\"\"\n",
    "    Save the trained model as a pickle file.\n",
    "\n",
    "    Args:\n",
    "    model: The trained model.\n",
    "    model_filepath (str): The file path where the model should be saved.\n",
    "    \"\"\"\n",
    "    joblib.dump(model, model_filepath)\n",
    "\n",
    "def run_pipeline(data_file, model_filepath):\n",
    "    \"\"\"\n",
    "    Execute the full pipeline: load data, build the model, train it, and export the model.\n",
    "\n",
    "    Args:\n",
    "    data_file (str): The file path of the CSV dataset.\n",
    "    model_filepath (str): The file path where the model should be saved.\n",
    "    \"\"\"\n",
    "    X, y = load_data(data_file)\n",
    "    model = build_model()\n",
    "    model = train(X, y, model)\n",
    "    export_model(model, model_filepath)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) == 3:\n",
    "        data_file = sys.argv[1]\n",
    "        model_filepath = sys.argv[2]\n",
    "        \n",
    "        print(f'Running pipeline for dataset: {data_file}')\n",
    "        run_pipeline(data_file, model_filepath)\n",
    "        print(f'Model saved to: {model_filepath}')\n",
    "    else:\n",
    "        print('Please provide the filepath of the dataset and the filepath to save the model as arguments.')\n",
    "        print('Example: python train_classifier.py data/messages.csv model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
